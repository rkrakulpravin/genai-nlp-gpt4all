{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2420036e-ce44-472a-9be0-4a849eb5978f",
   "metadata": {},
   "source": [
    "# tiktoken - A fast tokenizer library by OpenAI for counting tokens used in language models like GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df34b40-533a-41c5-9165-c9d841f1d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48e440c4-84e9-4395-85bd-2effcdc4a2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: [42821, 402, 367]\n",
      "Token count: 3\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")  # used by GPT-4, GPT-3.5\n",
    "tokens = enc.encode(\"Excavation\")\n",
    "\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"Token count:\", len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba6da1c",
   "metadata": {},
   "source": [
    "# Loading the Downloaded Model and Importing the Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c279d6-a896-4617-84c0-b183e2cc7d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install GPT4All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8add1a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded. Number of rows: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>provider_name</th>\n",
       "      <th>npi</th>\n",
       "      <th>taxonomy</th>\n",
       "      <th>eligibility_start</th>\n",
       "      <th>eligibility_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dr. Smith</td>\n",
       "      <td>1234567890</td>\n",
       "      <td>123456ZZ1</td>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>12/31/2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Jones</td>\n",
       "      <td>2345678901</td>\n",
       "      <td>987654ZZ2</td>\n",
       "      <td>06/15/2021</td>\n",
       "      <td>06/14/2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr. Lee</td>\n",
       "      <td>3456789012</td>\n",
       "      <td>123456ZZ1</td>\n",
       "      <td>01/01/2023</td>\n",
       "      <td>12/31/2026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  provider_name         npi   taxonomy eligibility_start eligibility_end\n",
       "0     Dr. Smith  1234567890  123456ZZ1        01/01/2020      12/31/2025\n",
       "1     Dr. Jones  2345678901  987654ZZ2        06/15/2021      06/14/2024\n",
       "2       Dr. Lee  3456789012  123456ZZ1        01/01/2023      12/31/2026"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from gpt4all import GPT4All\n",
    "\n",
    "df = pd.read_csv(\"sample_ahca_pml.csv\")\n",
    "print(\"Data loaded. Number of rows:\", len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a4da80-a98f-415e-b8d4-9a56527c7d72",
   "metadata": {},
   "source": [
    "# Hybrid Workflow: Automating Eligibility Checks and Explaining Results via LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c6c891-40c6-4397-a646-56ff49074e6e",
   "metadata": {},
   "source": [
    "using an LLM directly to reason over 200,000 rows of structured data is highly inefficient, and in most cases, completely impractical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7011d694",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_eligibility(provider_name, taxonomy, dos_str):\n",
    "    try:\n",
    "        dos = datetime.strptime(dos_str, \"%m/%d/%Y\")\n",
    "        match = df[\n",
    "            (df['provider_name'].str.lower() == provider_name.lower()) &\n",
    "            (df['taxonomy'].str.upper() == taxonomy.upper())\n",
    "        ]\n",
    "        for _, row in match.iterrows():\n",
    "            start = datetime.strptime(row['eligibility_start'], \"%m/%d/%Y\")\n",
    "            end = datetime.strptime(row['eligibility_end'], \"%m/%d/%Y\")\n",
    "            if start <= dos <= end:\n",
    "                return True, f\"Yes, {provider_name} can submit claims with taxonomy {taxonomy} on {dos_str}.\"\n",
    "        return False, f\"{provider_name} is not eligible for taxonomy {taxonomy} on {dos_str}.\"\n",
    "    except Exception as e:\n",
    "        return False, f\"Error: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "225fc525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load libllamamodel-mainline-cuda-avxonly.so: dlopen: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "Failed to load libllamamodel-mainline-cuda.so: dlopen: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "warning: model 'mistral-7b-openorca.Q4_K_M.gguf' is out-of-date, please check for an updated version\n"
     ]
    }
   ],
   "source": [
    "from gpt4all import GPT4All\n",
    "\n",
    "# Replace with the actual full path to your .gguf file\n",
    "gpt_model = GPT4All(model_name=\"mistral-7b-openorca.Q4_K_M.gguf\", model_path=\".\")\n",
    "\n",
    "def explain_with_local_llm(base_msg):\n",
    "    prompt = (\n",
    "        \"You are a helpful assistant. Your job is to explain the following statement \"\n",
    "        \"in simpler terms for someone without medical billing knowledge:\\n\\n\"\n",
    "        f\"{base_msg}\\n\\n\"\n",
    "        \"Explain this clearly and concisely.\"\n",
    "    )\n",
    "    print(f\"\\nPrompt:\\n{prompt}\\n\")\n",
    "    response = gpt_model.generate(prompt, max_tokens=200, temp=0.7, top_k=40)\n",
    "    print(\"\\nRaw LLM Response:\", repr(response))\n",
    "    return response.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77979fc4-63e1-4b32-9789-b177b3ac1c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gpt4all.gpt4all.GPT4All object at 0x7fd6daf800d0>\n"
     ]
    }
   ],
   "source": [
    "print(gpt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1f77fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: Yes, Dr. Smith can submit claims with taxonomy 123456ZZ1 on 10/01/2025.\n",
      "\n",
      "Prompt:\n",
      "You are a helpful assistant. Your job is to explain the following statement in simpler terms for someone without medical billing knowledge:\n",
      "\n",
      "Yes, Dr. Smith can submit claims with taxonomy 123456ZZ1 on 10/01/2025.\n",
      "\n",
      "Explain this clearly and concisely.\n",
      "\n",
      "\n",
      "Raw LLM Response: '\\n\\nDr. Smith is a healthcare professional who has the ability to send in medical billing information for their patients. The statement you provided talks about a specific code, called \"taxonomy,\" which is like an address that helps identify certain services or procedures performed on a patient. In this case, the taxonomy number is 123456ZZ1.\\n\\nNow, Dr. Smith can use this taxonomy to submit claims for their patients starting from October 1st, 2025 (10/01/2025). This means that they will be able to send in the necessary information about a patient\\'s treatment and receive payment or reimbursement for it.'\n",
      "\n",
      "Local GPT4All Response:\n",
      "Dr. Smith is a healthcare professional who has the ability to send in medical billing information for their patients. The statement you provided talks about a specific code, called \"taxonomy,\" which is like an address that helps identify certain services or procedures performed on a patient. In this case, the taxonomy number is 123456ZZ1.\n",
      "\n",
      "Now, Dr. Smith can use this taxonomy to submit claims for their patients starting from October 1st, 2025 (10/01/2025). This means that they will be able to send in the necessary information about a patient's treatment and receive payment or reimbursement for it.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "provider_name = \"Dr. Smith\"\n",
    "taxonomy = \"123456ZZ1\"\n",
    "dos_str = \"10/01/2025\"\n",
    "\n",
    "eligible, base_msg = check_eligibility(provider_name, taxonomy, dos_str)\n",
    "print(\"Result:\", base_msg)\n",
    "\n",
    "llm_response = explain_with_local_llm(base_msg)\n",
    "print(\"\\nLocal GPT4All Response:\")\n",
    "print(llm_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeca8102-4131-457a-9994-209d220a98e8",
   "metadata": {},
   "source": [
    "# Fully LLM-Driven Eligibility Assessment and Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e2fd63-715f-4f39-986e-333b6ee42326",
   "metadata": {},
   "source": [
    "##### Limitations of an LLM-Only Approach: Impractical and Non-Scalable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46b10f15-6010-4d27-b9e0-abd2aa88365f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found model file at 'mistral-7b-openorca.Q4_K_M.gguf'\n",
      "warning: model 'mistral-7b-openorca.Q4_K_M.gguf' is out-of-date, please check for an updated version\n"
     ]
    }
   ],
   "source": [
    "from gpt4all import GPT4All\n",
    "\n",
    "# Step 1: Load the model\n",
    "gpt_model = GPT4All(\n",
    "    model_name=\"mistral-7b-openorca.Q4_K_M.gguf\",\n",
    "    model_path=\".\",           # current directory\n",
    "    n_threads=4,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Step 2: Convert eligibility table into readable text\n",
    "eligibility_data = \"\"\"\n",
    "Here is the provider eligibility data:\n",
    "\n",
    "Dr. Smith, NPI 1234567890, Taxonomy 123456ZZ1, Eligible from 01/01/2020 to 12/31/2025\n",
    "Dr. Jones, NPI 2345678901, Taxonomy 987654ZZ2, Eligible from 06/15/2021 to 06/14/2024\n",
    "Dr. Lee, NPI 3456789012, Taxonomy 123456ZZ1, Eligible from 01/01/2023 to 12/31/2026\n",
    "\"\"\"\n",
    "\n",
    "# Step 3: Function to ask question using the LLM\n",
    "def ask_llm_directly(data_text, question):\n",
    "    full_prompt = (\n",
    "        f\"{data_text}\\n\\n\"\n",
    "        f\"Based on the above information, answer this question clearly:\\n{question}\"\n",
    "    )\n",
    "    print(\"\\nPrompt sent to LLM:\\n\", full_prompt)\n",
    "    response = gpt_model.generate(full_prompt, max_tokens=200, temp=0.7, top_k=40)\n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "437fbaee-f771-4e7e-b4ab-4bd0e0d97186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Example question\n",
    "question = \"Is Dr. Smith eligible to submit claims with taxonomy 123456ZZ1 on 10/01/2025?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04dc349c-cc0d-4e95-8199-799b2a18b66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt sent to LLM:\n",
      " \n",
      "Here is the provider eligibility data:\n",
      "\n",
      "Dr. Smith, NPI 1234567890, Taxonomy 123456ZZ1, Eligible from 01/01/2020 to 12/31/2025\n",
      "Dr. Jones, NPI 2345678901, Taxonomy 987654ZZ2, Eligible from 06/15/2021 to 06/14/2024\n",
      "Dr. Lee, NPI 3456789012, Taxonomy 123456ZZ1, Eligible from 01/01/2023 to 12/31/2026\n",
      "\n",
      "\n",
      "Based on the above information, answer this question clearly:\n",
      "Is Dr. Smith eligible to submit claims with taxonomy 123456ZZ1 on 10/01/2025?\n",
      "\n",
      "LLM Response:\n",
      "Yes, Dr. Smith is eligible to submit claims with taxonomy 123456ZZ1 on 10/01/2025 because his eligibility period includes this date (from 01/01/2020 to 12/31/2025).\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Run and print\n",
    "response = ask_llm_directly(eligibility_data, question)\n",
    "print(\"\\nLLM Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "319f3e80-b5f0-4ff1-a1e0-c3e74bfa28fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Was the NPI 3456789012 eligible on 1/1/2010?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "472dba57-6b63-479a-8b4e-afaaf98cba2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt sent to LLM:\n",
      " \n",
      "Here is the provider eligibility data:\n",
      "\n",
      "Dr. Smith, NPI 1234567890, Taxonomy 123456ZZ1, Eligible from 01/01/2020 to 12/31/2025\n",
      "Dr. Jones, NPI 2345678901, Taxonomy 987654ZZ2, Eligible from 06/15/2021 to 06/14/2024\n",
      "Dr. Lee, NPI 3456789012, Taxonomy 123456ZZ1, Eligible from 01/01/2023 to 12/31/2026\n",
      "\n",
      "\n",
      "Based on the above information, answer this question clearly:\n",
      "Was the NPI 3456789012 eligible on 1/1/2010?\n",
      "\n",
      "LLM Response:\n",
      "No, Dr. Lee's NPI (3456789012) was not eligible on January 1st, 2010 as their eligibility period starts from January 1st, 2023.\n"
     ]
    }
   ],
   "source": [
    "response = ask_llm_directly(eligibility_data, question)\n",
    "print(\"\\nLLM Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02f6bff6-8b66-48e9-ae76-18214d692577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt sent to LLM:\n",
      " \n",
      "Here is the provider eligibility data:\n",
      "\n",
      "Dr. Smith, NPI 1234567890, Taxonomy 123456ZZ1, Eligible from 01/01/2020 to 12/31/2025\n",
      "Dr. Jones, NPI 2345678901, Taxonomy 987654ZZ2, Eligible from 06/15/2021 to 06/14/2024\n",
      "Dr. Lee, NPI 3456789012, Taxonomy 123456ZZ1, Eligible from 01/01/2023 to 12/31/2026\n",
      "\n",
      "\n",
      "Based on the above information, answer this question clearly:\n",
      "Was the NPI 3456789012 allowed to submit 123456ZZ1 taxonomy code?\n",
      "\n",
      "LLM Response:\n",
      "Yes, Dr. Lee with NPI 3456789012 was allowed to submit the 123456ZZ1 taxonomy code as per the given eligibility data. The eligible period for this taxonomy is from 01/01/2023 to 12/31/2026, and Dr. Lee's NPI matches with that of the allowed provider.\n"
     ]
    }
   ],
   "source": [
    "question = \"Was the NPI 3456789012 allowed to submit 123456ZZ1 taxonomy code?\"\n",
    "\n",
    "response = ask_llm_directly(eligibility_data, question)\n",
    "print(\"\\nLLM Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea50af06-072d-42a3-b9c9-0d65e77f0363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt sent to LLM:\n",
      " \n",
      "Here is the provider eligibility data:\n",
      "\n",
      "Dr. Smith, NPI 1234567890, Taxonomy 123456ZZ1, Eligible from 01/01/2020 to 12/31/2025\n",
      "Dr. Jones, NPI 2345678901, Taxonomy 987654ZZ2, Eligible from 06/15/2021 to 06/14/2024\n",
      "Dr. Lee, NPI 3456789012, Taxonomy 123456ZZ1, Eligible from 01/01/2023 to 12/31/2026\n",
      "\n",
      "\n",
      "Based on the above information, answer this question clearly:\n",
      "Was the NPI 3456789012 allowed to submit 123456ZZ1 taxonomy code on 1st January 2025?\n",
      "\n",
      "LLM Response:\n",
      "No, Dr. Lee with NPI 3456789012 was not allowed to submit the 123456ZZ1 taxonomy code on 1st January 2025 because his eligibility period ends on 31st December 2024.\n",
      "\n",
      "Here is a summary of their eligibilities:\n",
      "\n",
      "Dr. Smith - Eligible from 01/01/2020 to 12/31/2025 (allowed to submit the taxonomy code)\n",
      "Dr. Jones - Eligible from 06/15/2021 to 06/14/2024 (not allowed to submit the taxonomy code on 1st January 2025)\n",
      "Dr. Lee - Eligible from 01/01/2023 to 12/31/2\n"
     ]
    }
   ],
   "source": [
    "question = \"Was the NPI 3456789012 allowed to submit 123456ZZ1 taxonomy code on 1st January 2025?\"\n",
    "\n",
    "response = ask_llm_directly(eligibility_data, question)\n",
    "print(\"\\nLLM Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2be7704f-ba4f-4c50-a82c-89ce2ebc1596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt sent to LLM:\n",
      " \n",
      "Here is the provider eligibility data:\n",
      "\n",
      "Dr. Smith, NPI 1234567890, Taxonomy 123456ZZ1, Eligible from 01/01/2020 to 12/31/2025\n",
      "Dr. Jones, NPI 2345678901, Taxonomy 987654ZZ2, Eligible from 06/15/2021 to 06/14/2024\n",
      "Dr. Lee, NPI 3456789012, Taxonomy 123456ZZ1, Eligible from 01/01/2023 to 12/31/2026\n",
      "\n",
      "\n",
      "Based on the above information, answer this question clearly:\n",
      "Was the NPI 3456789012 allowed to submit 123456ZZ1 taxonomy code on 1st January 2024? Summarize this article in 2 bullet points.\n",
      "\n",
      "LLM Response:\n",
      "The NPI 3456789012 was not allowed to submit the 123456ZZ1 taxonomy code on 1st January 2024, as their eligibility period for that taxonomy is from 1st January 2023 to 31st December 2026.\n",
      "\n",
      "Article Summary:\n",
      "- NPI 3456789012 was not allowed to submit the 123456ZZ1 taxonomy code on 1st January 2024.\n",
      "- Their eligibility period for that taxonomy is from 1st January 2023 to 31st December 2026.\n"
     ]
    }
   ],
   "source": [
    "question = \"Was the NPI 3456789012 allowed to submit 123456ZZ1 taxonomy code on 1st January 2024? Summarize this article in 2 bullet points.\"\n",
    "\n",
    "response = ask_llm_directly(eligibility_data, question)\n",
    "print(\"\\nLLM Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7faf5e-3004-44f4-bcfb-21882402b160",
   "metadata": {},
   "source": [
    "# Leveraging RAG for Faster, Context-Aware Eligibility Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa682a0f-8e84-42ca-8da0-d487c8663169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: model 'mistral-7b-openorca.Q4_K_M.gguf' is out-of-date, please check for an updated version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final LLM Explanation:\n",
      "\n",
      "\n",
      "Dr. Lee, a healthcare professional with the National Provider Identifier (NPI) number 3456789012, is allowed to use taxonomy code 123456ZZ1 for their medical services starting from January 1st, 2024. This eligibility period lasts until December 31st, 2026.\n",
      "\n",
      "Taxonomy codes are used by healthcare providers and insurance companies to classify the specific medical procedures or services they offer. In this case, Dr. Lee can use taxonomy code 123456ZZ1 for their practice during the specified eligibility period.\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    {\"provider\": \"Dr. Smith\", \"npi\": \"1234567890\", \"taxonomy\": \"123456ZZ1\", \"start\": \"01/01/2020\", \"end\": \"12/31/2025\"},\n",
    "    {\"provider\": \"Dr. Jones\", \"npi\": \"2345678901\", \"taxonomy\": \"987654ZZ2\", \"start\": \"06/15/2021\", \"end\": \"06/14/2024\"},\n",
    "    {\"provider\": \"Dr. Lee\", \"npi\": \"3456789012\", \"taxonomy\": \"123456ZZ1\", \"start\": \"01/01/2023\", \"end\": \"12/31/2026\"},\n",
    "]\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from gpt4all import GPT4All\n",
    "\n",
    "# Load the local LLM\n",
    "gpt_model = GPT4All(\"mistral-7b-openorca.Q4_K_M.gguf\", model_path=\".\", n_threads=4, verbose=False)\n",
    "\n",
    "# Example question\n",
    "npi_query = \"3456789012\"\n",
    "taxonomy_query = \"123456ZZ1\"\n",
    "date_str = \"01/01/2024\"\n",
    "\n",
    "# RAG: Retrieve the matching record\n",
    "def retrieve_provider_record(npi, taxonomy, data):\n",
    "    return next((row for row in data if row[\"npi\"] == npi and row[\"taxonomy\"] == taxonomy), None)\n",
    "\n",
    "# Validation logic\n",
    "def validate_eligibility(record, date_str):\n",
    "    try:\n",
    "        check_date = datetime.strptime(date_str, \"%m/%d/%Y\")\n",
    "        start_date = datetime.strptime(record[\"start\"], \"%m/%d/%Y\")\n",
    "        end_date = datetime.strptime(record[\"end\"], \"%m/%d/%Y\")\n",
    "        return start_date <= check_date <= end_date\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Ask the LLM to explain based on the validated result\n",
    "def explain_eligibility(record, date_str, is_eligible):\n",
    "    status = \"eligible\" if is_eligible else \"not eligible\"\n",
    "    prompt = (\n",
    "        f\"{record['provider']} (NPI {record['npi']}) is {status} to submit taxonomy code {record['taxonomy']} \"\n",
    "        f\"on {date_str}. Their eligibility period is from {record['start']} to {record['end']}.\\n\\n\"\n",
    "        \"Explain this eligibility status in simple terms.\"\n",
    "    )\n",
    "    return gpt_model.generate(prompt, max_tokens=150)\n",
    "\n",
    "# Run the flow\n",
    "record = retrieve_provider_record(npi_query, taxonomy_query, data)\n",
    "\n",
    "if record:\n",
    "    is_eligible = validate_eligibility(record, date_str)\n",
    "    response = explain_eligibility(record, date_str, is_eligible)\n",
    "    print(\"✅ Final LLM Explanation:\")\n",
    "    print(response)\n",
    "else:\n",
    "    print(\"❌ No matching provider found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2849b17-8a3f-43cd-863a-6d262a851dda",
   "metadata": {},
   "source": [
    "# RAG + NLP - Transforming User Questions into Structured Fields via LLM NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50d03b0b-21b4-484c-8382-47d2f39b12e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: model 'mistral-7b-openorca.Q4_K_M.gguf' is out-of-date, please check for an updated version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Original question:\n",
      "Can you check if NPI 3456789012 can submit taxonomy 123456ZZ1 on January 1st 2024?\n",
      "\n",
      "✅ Parsed:\n",
      "NPI: 3456789012\n",
      "Taxonomy: 123456ZZ1\n",
      "Date: 01/01/2024\n",
      "\n",
      "\n",
      "✅ Final Explanation:\n",
      "\n",
      "\n",
      "Dr. Lee, a medical professional with the National Provider Identifier (NPI) number 3456789012, is allowed to use taxonomy code 123456ZZ1 for their services starting on January 1st, 2024. This eligibility period lasts until December 31st, 2026.\n",
      "\n",
      "In this context:\n",
      "- NPI number refers to a unique identification number assigned by the National Plan and Provider Enumeration System (NPPES) for healthcare providers in the United States.\n",
      "- Taxonomy code is a standardized system of codes used to classify medical services, procedures, or items\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from gpt4all import GPT4All\n",
    "from dateutil.parser import parse as date_parse\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    {\"provider\": \"Dr. Smith\", \"npi\": \"1234567890\", \"taxonomy\": \"123456ZZ1\", \"start\": \"01/01/2020\", \"end\": \"12/31/2025\"},\n",
    "    {\"provider\": \"Dr. Jones\", \"npi\": \"2345678901\", \"taxonomy\": \"987654ZZ2\", \"start\": \"06/15/2021\", \"end\": \"06/14/2024\"},\n",
    "    {\"provider\": \"Dr. Lee\", \"npi\": \"3456789012\", \"taxonomy\": \"123456ZZ1\", \"start\": \"01/01/2023\", \"end\": \"12/31/2026\"},\n",
    "]\n",
    "\n",
    "# Load local LLM\n",
    "gpt_model = GPT4All(\"mistral-7b-openorca.Q4_K_M.gguf\", model_path=\".\", n_threads=4, verbose=False)\n",
    "\n",
    "# Step 1: Extract structured data from natural language question using LLM\n",
    "def extract_query_fields(question):\n",
    "    prompt = (\n",
    "        \"Extract the NPI, taxonomy code, and date from this question:\\n\"\n",
    "        f\"\\\"{question}\\\"\\n\\n\"\n",
    "        \"Return the result in this format:\\n\"\n",
    "        \"NPI: <npi_number>\\nTaxonomy: <taxonomy_code>\\nDate: <mm/dd/yyyy>\"\n",
    "    )\n",
    "    response = gpt_model.generate(prompt, max_tokens=100)\n",
    "    lines = response.strip().splitlines()\n",
    "\n",
    "    npi = taxonomy = date_str = None\n",
    "    for line in lines:\n",
    "        if line.lower().startswith(\"npi:\"):\n",
    "            npi = line.split(\":\", 1)[1].strip()\n",
    "        elif line.lower().startswith(\"taxonomy:\"):\n",
    "            taxonomy = line.split(\":\", 1)[1].strip()\n",
    "        elif line.lower().startswith(\"date:\"):\n",
    "            try:\n",
    "                # Convert anything to mm/dd/yyyy\n",
    "                date_obj = date_parse(line.split(\":\", 1)[1].strip())\n",
    "                date_str = date_obj.strftime(\"%m/%d/%Y\")\n",
    "            except:\n",
    "                pass\n",
    "    return npi, taxonomy, date_str\n",
    "\n",
    "# Step 2: Retrieve matching provider\n",
    "def retrieve_provider_record(npi, taxonomy, data):\n",
    "    return next((row for row in data if row[\"npi\"] == npi and row[\"taxonomy\"] == taxonomy), None)\n",
    "\n",
    "# Step 3: Validate eligibility\n",
    "def validate_eligibility(record, date_str):\n",
    "    try:\n",
    "        check_date = datetime.strptime(date_str, \"%m/%d/%Y\")\n",
    "        start_date = datetime.strptime(record[\"start\"], \"%m/%d/%Y\")\n",
    "        end_date = datetime.strptime(record[\"end\"], \"%m/%d/%Y\")\n",
    "        return start_date <= check_date <= end_date\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Step 4: Explain eligibility\n",
    "def explain_eligibility(record, date_str, is_eligible):\n",
    "    status = \"eligible\" if is_eligible else \"not eligible\"\n",
    "    prompt = (\n",
    "        f\"{record['provider']} (NPI {record['npi']}) is {status} to submit taxonomy code {record['taxonomy']} \"\n",
    "        f\"on {date_str}. Their eligibility period is from {record['start']} to {record['end']}.\\n\\n\"\n",
    "        \"Explain this eligibility status in simple terms.\"\n",
    "    )\n",
    "    return gpt_model.generate(prompt, max_tokens=150)\n",
    "\n",
    "# Step 5: Full pipeline\n",
    "def handle_question(natural_language_input):\n",
    "    print(f\"\\n🧠 Original question:\\n{natural_language_input}\\n\")\n",
    "    npi, taxonomy, date_str = extract_query_fields(natural_language_input)\n",
    "\n",
    "    if not (npi and taxonomy and date_str):\n",
    "        print(\"❌ Failed to extract structured fields from input.\")\n",
    "        return\n",
    "\n",
    "    print(f\"✅ Parsed:\\nNPI: {npi}\\nTaxonomy: {taxonomy}\\nDate: {date_str}\\n\")\n",
    "\n",
    "    record = retrieve_provider_record(npi, taxonomy, data)\n",
    "    if record:\n",
    "        is_eligible = validate_eligibility(record, date_str)\n",
    "        response = explain_eligibility(record, date_str, is_eligible)\n",
    "        print(\"\\n✅ Final Explanation:\")\n",
    "        print(response)\n",
    "    else:\n",
    "        print(\"❌ No matching provider found.\")\n",
    "\n",
    "# Example call\n",
    "handle_question(\"Can you check if NPI 3456789012 can submit taxonomy 123456ZZ1 on January 1st 2024?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "739a0756-7a14-4157-9164-cc4cb38294d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 Original question:\n",
      "What all taxonomies can NPI 3456789012 submit on January 1st 2024?\n",
      "\n",
      "✅ Parsed:\n",
      "NPI: 3456789012\n",
      "Taxonomy: ZZZ\n",
      "Date: 01/01/2024\n",
      "\n",
      "❌ No matching provider found.\n"
     ]
    }
   ],
   "source": [
    "# Example call\n",
    "handle_question(\"What all taxonomies can NPI 3456789012 submit on January 1st 2024?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46e53cc-bf65-4f28-a76b-b97b1cd4c04e",
   "metadata": {},
   "source": [
    "# Adding Intent Detection to Improve Question Handling and Response Generation + Making Changes to help Understand, Debug and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edff16a1-c375-4963-9244-93d9970bd1f9",
   "metadata": {},
   "source": [
    "Natural language is often ambiguous. A question like:\n",
    "\n",
    "\"What can NPI 1234567890 submit on Jan 1st?\"\n",
    "\n",
    "...could mean:\n",
    "\n",
    "“Is this NPI eligible for a specific taxonomy?”\n",
    "\n",
    "“Which taxonomy codes are eligible for this NPI?”\n",
    "\n",
    "“Which providers can submit this taxonomy?”\n",
    "\n",
    "Intent detection helps disambiguate the user's goal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69055ee8-5982-48b5-8e14-a9eb20c92952",
   "metadata": {},
   "source": [
    "This version includes print statements for LLM prompts and responses, making it much easier to:\n",
    "\n",
    "Understand what’s being sent to the model\n",
    "\n",
    "Debug or trace errors in intent or field extraction\n",
    "\n",
    "Evaluate how well the model performs in different scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f44abd5d-60fa-4b4c-ac68-c77749f95c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: model 'mistral-7b-openorca.Q4_K_M.gguf' is out-of-date, please check for an updated version\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from gpt4all import GPT4All\n",
    "from dateutil.parser import parse as date_parse\n",
    "import re\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Sample structured data\n",
    "# -----------------------------\n",
    "data = [\n",
    "    {\"provider\": \"Dr. Smith\", \"npi\": \"1234567890\", \"taxonomy\": \"123456ZZ1\", \"start\": \"01/01/2020\", \"end\": \"12/31/2025\"},\n",
    "    {\"provider\": \"Dr. Jones\", \"npi\": \"2345678901\", \"taxonomy\": \"987654ZZ2\", \"start\": \"06/15/2021\", \"end\": \"06/14/2024\"},\n",
    "    {\"provider\": \"Dr. Lee\", \"npi\": \"3456789012\", \"taxonomy\": \"123456ZZ1\", \"start\": \"01/01/2023\", \"end\": \"12/31/2026\"},\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Load local LLM\n",
    "# -----------------------------\n",
    "gpt_model = GPT4All(\"mistral-7b-openorca.Q4_K_M.gguf\", model_path=\".\", n_threads=4, verbose=False)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Intent detection using LLM\n",
    "# -----------------------------\n",
    "def detect_intent(question):\n",
    "    prompt = (\n",
    "        \"Classify the following question into one of these types:\\n\"\n",
    "        \"- single-check\\n- list-taxonomies\\n- list-npis\\n\"\n",
    "        f\"\\nQuestion: {question}\\nAnswer:\"\n",
    "    )\n",
    "    print(\"\\n📤 Prompt to LLM (Intent):\\n\" + prompt)\n",
    "    response = gpt_model.generate(prompt, max_tokens=10).strip().lower()\n",
    "    print(\"📥 LLM Response (Intent):\\n\" + response)\n",
    "    return response\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Extract fields (NPI, taxonomy, date)\n",
    "# -----------------------------\n",
    "def extract_fields(question):\n",
    "    prompt = (\n",
    "        f\"Extract NPI, taxonomy code, and date from this question (if present):\\n\"\n",
    "        f\"\\\"{question}\\\"\\n\\nReturn format:\\nNPI: <npi>\\nTaxonomy: <taxonomy>\\nDate: <mm/dd/yyyy>\"\n",
    "    )\n",
    "    print(\"\\n📤 Prompt to LLM (Field Extraction):\\n\" + prompt)\n",
    "    response = gpt_model.generate(prompt, max_tokens=100)\n",
    "    print(\"📥 LLM Response (Field Extraction):\\n\" + response)\n",
    "\n",
    "    lines = response.strip().splitlines()\n",
    "    npi = taxonomy = date_str = None\n",
    "    for line in lines:\n",
    "        if line.lower().startswith(\"npi:\"):\n",
    "            npi = line.split(\":\", 1)[1].strip()\n",
    "        elif line.lower().startswith(\"taxonomy:\"):\n",
    "            taxonomy = line.split(\":\", 1)[1].strip()\n",
    "        elif line.lower().startswith(\"date:\"):\n",
    "            try:\n",
    "                date_obj = date_parse(line.split(\":\", 1)[1].strip())\n",
    "                date_str = date_obj.strftime(\"%m/%d/%Y\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    if not npi:\n",
    "        match = re.search(r'npi[\\s:]*([0-9]{10})', question.lower())\n",
    "        if match:\n",
    "            npi = match.group(1)\n",
    "    if not date_str:\n",
    "        try:\n",
    "            date_obj = date_parse(question, fuzzy=True)\n",
    "            date_str = date_obj.strftime(\"%m/%d/%Y\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if taxonomy and '[list' in taxonomy.lower():\n",
    "        taxonomy = None\n",
    "\n",
    "    return npi, taxonomy, date_str\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Logic functions\n",
    "# -----------------------------\n",
    "def retrieve_provider_record(npi, taxonomy, data):\n",
    "    return next((row for row in data if row[\"npi\"] == npi and row[\"taxonomy\"] == taxonomy), None)\n",
    "\n",
    "def validate_eligibility(record, date_str):\n",
    "    check_date = datetime.strptime(date_str, \"%m/%d/%Y\")\n",
    "    start_date = datetime.strptime(record[\"start\"], \"%m/%d/%Y\")\n",
    "    end_date = datetime.strptime(record[\"end\"], \"%m/%d/%Y\")\n",
    "    return start_date <= check_date <= end_date\n",
    "\n",
    "def get_all_eligible_taxonomies(npi, date_str, data):\n",
    "    check_date = datetime.strptime(date_str, \"%m/%d/%Y\")\n",
    "    return [row for row in data if row[\"npi\"] == npi and datetime.strptime(row[\"start\"], \"%m/%d/%Y\") <= check_date <= datetime.strptime(row[\"end\"], \"%m/%d/%Y\")]\n",
    "\n",
    "def get_all_eligible_providers(taxonomy, date_str, data):\n",
    "    check_date = datetime.strptime(date_str, \"%m/%d/%Y\")\n",
    "    return [row for row in data if row[\"taxonomy\"] == taxonomy and datetime.strptime(row[\"start\"], \"%m/%d/%Y\") <= check_date <= datetime.strptime(row[\"end\"], \"%m/%d/%Y\")]\n",
    "\n",
    "def explain_results(prompt):\n",
    "    print(\"\\n📤 Prompt to LLM (Explanation):\\n\" + prompt)\n",
    "    response = gpt_model.generate(prompt, max_tokens=150)\n",
    "    print(\"📥 LLM Response (Explanation):\\n\" + response)\n",
    "    return response\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Unified handler\n",
    "# -----------------------------\n",
    "def handle_question(question):\n",
    "    print(f\"\\n🧠 User Question: {question}\\n\")\n",
    "    intent = detect_intent(question).lower().strip()\n",
    "\n",
    "    if \"single\" in intent:\n",
    "        intent = \"single-check\"\n",
    "    elif \"taxonomies\" in intent or \"taxonomy\" in intent:\n",
    "        intent = \"list-taxonomies\"\n",
    "    elif \"npi\" in intent:\n",
    "        intent = \"list-npis\"\n",
    "\n",
    "    npi, taxonomy, date_str = extract_fields(question)\n",
    "\n",
    "    print(f\"🔎 Detected Intent: {intent}\")\n",
    "    print(f\"🧾 Extracted → NPI: {npi}, Taxonomy: {taxonomy}, Date: {date_str}\")\n",
    "\n",
    "    if intent == \"single-check\" and npi and taxonomy and date_str:\n",
    "        record = retrieve_provider_record(npi, taxonomy, data)\n",
    "        if record:\n",
    "            is_eligible = validate_eligibility(record, date_str)\n",
    "            status = \"eligible\" if is_eligible else \"not eligible\"\n",
    "            prompt = (\n",
    "                f\"{record['provider']} (NPI {npi}) is {status} to submit taxonomy code {taxonomy} on {date_str}. \"\n",
    "                f\"Eligibility: {record['start']} to {record['end']}.\\nExplain this eligibility in simple terms.\"\n",
    "            )\n",
    "            print(\"\\n✅ Final Explanation:\\n\" + explain_results(prompt))\n",
    "        else:\n",
    "            print(\"❌ No matching provider found.\")\n",
    "\n",
    "    elif intent == \"list-taxonomies\" and npi and date_str:\n",
    "        eligible = get_all_eligible_taxonomies(npi, date_str, data)\n",
    "        if eligible:\n",
    "            summary = \"\\n\".join([f\"- {row['taxonomy']} ({row['start']} to {row['end']})\" for row in eligible])\n",
    "            prompt = (\n",
    "                f\"On {date_str}, NPI {npi} is eligible to submit the following taxonomy codes:\\n{summary}\\n\"\n",
    "                f\"Explain this list in a user-friendly way.\"\n",
    "            )\n",
    "            print(\"\\n✅ Final Explanation:\\n\" + explain_results(prompt))\n",
    "        else:\n",
    "            print(\"❌ No eligible taxonomies found.\")\n",
    "\n",
    "    elif intent == \"list-npis\" and taxonomy and date_str:\n",
    "        eligible = get_all_eligible_providers(taxonomy, date_str, data)\n",
    "        if eligible:\n",
    "            summary = \"\\n\".join([f\"- {row['provider']} (NPI {row['npi']}, {row['start']} to {row['end']})\" for row in eligible])\n",
    "            prompt = (\n",
    "                f\"On {date_str}, the following providers are eligible to submit taxonomy code {taxonomy}:\\n{summary}\\n\"\n",
    "                f\"Summarize this for a user.\"\n",
    "            )\n",
    "            print(\"\\n✅ Final Explanation:\\n\" + explain_results(prompt))\n",
    "        else:\n",
    "            print(\"❌ No providers eligible for this taxonomy on the given date.\")\n",
    "\n",
    "    else:\n",
    "        print(\"❌ Could not parse intent or required fields from question.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9089acd0-6099-4b8e-a729-f4480318300f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 User Question: What all taxonomies can NPI 3456789012 submit on January 1st 2024?\n",
      "\n",
      "\n",
      "📤 Prompt to LLM (Intent):\n",
      "Classify the following question into one of these types:\n",
      "- single-check\n",
      "- list-taxonomies\n",
      "- list-npis\n",
      "\n",
      "Question: What all taxonomies can NPI 3456789012 submit on January 1st 2024?\n",
      "Answer:\n",
      "📥 LLM Response (Intent):\n",
      "the question is asking about the possible taxonomy subm\n",
      "\n",
      "📤 Prompt to LLM (Field Extraction):\n",
      "Extract NPI, taxonomy code, and date from this question (if present):\n",
      "\"What all taxonomies can NPI 3456789012 submit on January 1st 2024?\"\n",
      "\n",
      "Return format:\n",
      "NPI: <npi>\n",
      "Taxonomy: <taxonomy>\n",
      "Date: <mm/dd/yyyy>\n",
      "📥 LLM Response (Field Extraction):\n",
      "\n",
      "\n",
      "Example output for the given question:\n",
      "NPI: 3456789012\n",
      "Taxonomy: [list of taxonomies]\n",
      "Date: 01/01/2024\n",
      "🔎 Detected Intent: list-taxonomies\n",
      "🧾 Extracted → NPI: 3456789012, Taxonomy: None, Date: 01/01/2024\n",
      "\n",
      "📤 Prompt to LLM (Explanation):\n",
      "On 01/01/2024, NPI 3456789012 is eligible to submit the following taxonomy codes:\n",
      "- 123456ZZ1 (01/01/2023 to 12/31/2026)\n",
      "Explain this list in a user-friendly way.\n",
      "📥 LLM Response (Explanation):\n",
      "\n",
      "\n",
      "This statement means that on January 1, 2024, the National Provider Identifier (NPI) number 3456789012 will be allowed to use specific taxonomy codes for medical services and procedures. The taxonomy codes are a set of alphanumeric identifiers used by healthcare providers to categorize their services according to standardized classifications.\n",
      "\n",
      "In this case, the NPI number can only use one taxonomy code from January 1, 2023, to December 31, 2026: 123456ZZ1. This means that during these years, all medical services and procedures provided by the healthcare provider\n",
      "\n",
      "✅ Final Explanation:\n",
      "\n",
      "\n",
      "This statement means that on January 1, 2024, the National Provider Identifier (NPI) number 3456789012 will be allowed to use specific taxonomy codes for medical services and procedures. The taxonomy codes are a set of alphanumeric identifiers used by healthcare providers to categorize their services according to standardized classifications.\n",
      "\n",
      "In this case, the NPI number can only use one taxonomy code from January 1, 2023, to December 31, 2026: 123456ZZ1. This means that during these years, all medical services and procedures provided by the healthcare provider\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 7. Try it out\n",
    "# -----------------------------\n",
    "# Example questions:\n",
    "# handle_question(\"Can Dr. Lee (NPI 3456789012) submit taxonomy 123456ZZ1 on Jan 1, 2024?\")\n",
    "handle_question(\"What all taxonomies can NPI 3456789012 submit on January 1st 2024?\")\n",
    "# handle_question(\"Which NPIs can submit taxonomy 123456ZZ1 on 01/01/2024?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b4415f7-4aed-410a-9907-12935a7987a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze > requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
